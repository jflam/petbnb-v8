Got it. I’ll review the repository to understand how testing is currently set up, where Vitest and Jest are used, and whether the setup can be simplified or consolidated. I’ll identify the most appropriate way to ensure unit and API tests run correctly in CI, and propose necessary updates to the configuration and dependencies.

I’ll report back with a summary of the testing structure, any duplication or inconsistency, and a recommendation for how to simplify or unify the test tooling.


# Testing Setup in **ai-starter-app-postgis**: Vitest vs. Jest and Simplification

## Current Test File Organization (Unit vs. API Tests)

The repository has a **`tests/` directory** split into front-end and back-end subfolders:

* **Front-end unit tests** reside under **`tests/client/`**. These are typically React component or hook tests written in TypeScript (e.g. `Header.test.tsx` for a React component). They run in a browser-like environment (JSDOM) using **Vitest** and React Testing Library.
* **Back-end API tests** reside under **`tests/server/`**. These tests (e.g. `api.test.js`) target the Express API endpoints using **Jest** with Supertest. They are integration tests hitting the live Express app and database. For example, the API test file verifies routes like GET `/api/health` return the expected JSON and status codes.

This separation is also reflected in the project’s design document, which outlines using **Vitest** for front-end tests and **Jest** for back-end tests:

> “Unit — front‑end: Vitest 3 + RTL (React Testing Library)… Unit — back‑end: Jest 30… Integration API/DB: Jest + Supertest + **testcontainers**… Integration UI/API: Vitest + MSW…”

In summary, **Vitest is currently used for all client-side (unit/UI) tests**, while **Jest is used for server-side (API/DB) tests**.

## Test Execution Scripts and Configuration

The project’s **npm scripts** define how each test suite is run:

* **`npm run test:unit`** – Executes Vitest in run (CI) mode. This runs the tests under `tests/client/` using the Vitest config. Vitest is configured with a JSDOM environment and global test APIs for these front-end tests.
* **`npm run test:api`** – Executes Jest (with `jest.config.js`) in band (single-threaded) mode. This runs the tests under `tests/server/` using the Jest config. The Jest config targets only the server tests (`**/tests/server/**/*.test.js`) and uses a Node environment. The `--runInBand` flag ensures tests run sequentially in one process (important because a shared test database container is used).
* **`npm run test`** – A convenience script to run **all unit and API tests** in sequence by invoking both of the above scripts. (There is also a `test:e2e` for Playwright end-to-end tests, and a `test:all` that attempts to run unit, API, and e2e tests in parallel.)

In the **Vitest configuration** (`vitest.config.ts`), the tests are specifically **limited to the client folder** via an include pattern. Vitest is set to use JSDOM and includes a setup file for cleanup after each test. In contrast, the **Jest configuration** (`jest.config.js`) matches only the server tests and uses the Node test environment. This strict separation ensures Vitest only runs UI tests and Jest only runs API/DB tests.

**Dependencies:** All testing frameworks are defined in a single **root `package.json`** (this is *not* a multi-package monorepo – just one project). Both Vitest and Jest (plus related libraries) appear together in devDependencies. For example, the project includes `vitest` 3.x and `jest` 29.x, along with `@testing-library/*` packages for React, `babel-jest` and `ts-jest` for Jest transforms, etc. This single package.json and unified dependency list indicate a single project repository (the front-end and back-end share the same Node modules), rather than a structured monorepo with separate packages.

## Dual Test Runners: Rationale and Overhead

Using **two different test runners** was likely done to leverage each tool’s strengths in its domain. Vitest integrates tightly with Vite/ESM and is very fast for front-end testing, whereas Jest has a long history of robust Node.js testing and plugins. In fact, the implementation plan notes that the team chose to write the API tests in plain JS under Jest *“to avoid TypeScript/ESM complications”*. In other words, since the server code uses modern ESM and TypeScript, they sidestepped Jest’s friction with ESM by writing the tests in vanilla JS and using Babel to transform imports. This is a workaround to let Jest consume the ES module code. Vitest, on the other hand, runs the front-end TS/JS code natively through Vite’s ESM pipeline, so it doesn’t require such workarounds.

However, **maintaining two test frameworks side-by-side comes at a cost**:

* **Duplicate configuration and tooling:** There are separate configs (Vitest vs Jest), different setup files, and duplicate dev dependencies. For instance, both Vitest and Jest need to be configured for coverage reporting, environment, etc., increasing maintenance effort. The package.json includes Babel and ts-jest only to support Jest, which wouldn’t be needed if using one framework.
* **Complex CI integration:** Running two test suites means extra scripting to combine results. Currently, `npm run test` runs unit then API tests, and the project uses NYC/Codecov to aggregate coverage from both. This is more complex than using a single coverage tool. Ensuring both runners’ results are merged (and that both run reliably in CI) is additional overhead.
* **Inconsistent developer experience:** Developers have to remember two test commands and two ways of writing tests. For example, Vitest uses `expect` globally (with Vitest’s matcher extensions) and supports ESM out of the box, while Jest requires care with module imports (extensions, CJS/ESM differences) and uses its own global expect (with slightly different plugin syntax for things like `jest.fn()` vs Vitest’s `vi.fn()`). This can cause confusion when switching between test files.
* **Performance and environment differences:** Vitest is known for speed (thanks to Vite’s bundling and happy path for TS), whereas Jest spins up heavier Node processes. Using both means you don’t fully benefit from batching tests together. Also, the test environments differ (Vitest JSDOM vs. Jest Node) – for example, front-end tests have DOM globals, back-end tests do not. In principle a single runner could handle both scenarios with appropriate configuration, reducing context-switching between environments.

In short, while the current setup **works**, it is more complex than necessary for a project of this size. It was designed to demonstrate a comprehensive testing approach, but we can simplify it by standardizing on one test runner.

## Feasibility of Consolidating to One Test Runner

It is **feasible to consolidate** all the tests under **one framework**. Both Vitest and Jest are general-purpose enough to run front-end **and** back-end tests:

* **Using only Vitest:** Vitest can run *all* tests (including API/Node tests). It supports a Node environment as well as JSDOM. We could configure Vitest to include the `tests/server` files (not just client) and mark those tests to use a Node environment. For example, Vitest allows per-file environment overrides (via a comment like `// @vitest-environment node` at the top of a test file) to run certain tests in a pure Node context. The PostGIS integration can be handled in Vitest by using the same Testcontainers logic – Vitest tests can `import { startPg }` from the helper and invoke it in a `beforeAll`. There is nothing inherently Jest-specific about Testcontainers or Supertest; they are standard Node libraries that work in Vitest as well. In fact, since Vitest runs code via Vite’s ESM bundler, it may handle ES module imports more gracefully (no need for Babel transforms or `.js` extensions fixes that Jest required). **Vitest is already configured for TypeScript and JSDOM**, so our front-end tests would continue to work seamlessly. We would need to extend its configuration to also run the back-end tests and possibly add a global setup to start/stop the database container. Vitest v3 supports a `globalSetup` function in config, which could spin up the PostGIS container once for the entire test run, or we could simply call `startPg()` in a top-level test suite beforeAll. In summary, consolidating on Vitest is quite practical and would simplify handling of ESM/TypeScript (no Babel/ts-jest needed).

* **Using only Jest:** Jest can also be configured to run both suites, though it needs a bit more tweaking for the front-end. We would have to enable JSDOM for React component tests (Jest’s `testEnvironment` can be set to `"jsdom"` globally, or on a per-directory basis). Also, since our front-end tests are in TypeScript/JSX, we’d need to add a transform for `.tsx?/jsx?` files – for example, using **ts-jest** or Babel with a React preset – so that Jest can understand TSX. This is doable by adjusting `jest.config.js` (adding `transform` patterns for TypeScript and perhaps configuring moduleNameMapper for any Vite-specific import aliases like `"@"`). We’d also integrate the Testcontainers setup into Jest’s flow, likely by adding a **globalSetup** script to start the PostgreSQL container and a **globalTeardown** to stop it (instead of relying on an external `.env.test` or manual DB). Jest does support global setup/teardown out of the box. We’d run Jest in one go for all tests (possibly as separate projects or just one project), ensuring the Node environment is used for API tests (this could be handled by specifying a different testEnvironment for the API test files via a file header or jest config pattern). **Consolidating on Jest** would remove Vitest and Vite from testing, which might slow down front-end test execution and reintroduce some ESM friction (because our codebase is ESM). It’s workable, but we’d be effectively reverting to a more traditional Jest-only setup and losing some of Vitest’s niceties (like fast TS processing and native Vite module resolution).

**Which is more appropriate?** Given this project’s modern stack (Vite, ESM, React 18/19, etc.), **standardizing on Vitest is the more straightforward choice.** Vitest was already chosen for half the tests and has first-class support for both browser-like and Node environments. It will handle our TypeScript and ESM modules with zero fuss (no need for Babel or special transformers), and it runs tests blazingly fast. By contrast, while Jest can be made to work for everything, it would require additional configuration to handle the front-end side (and the ESM modules), essentially duplicating what Vite/Vitest gives us for free. In short, **Vitest can cover all use cases that Jest is covering, with less config complexity**, so it makes sense to unify on Vitest.

*(For completeness: if the team has a strong preference for Jest’s ecosystem or already-built mocks/snapshots, consolidating on Jest is possible. But given that the project is already set up with Vitest and Vite, the path of least resistance is to expand Vitest to cover API tests as well.)*

## Proposed Simplified Testing Setup (Consolidate on Vitest)

Below is a plan to **standardize all unit and integration tests on Vitest**, removing Jest entirely. This will simplify the configuration, reduce dependencies, and unify the testing workflow:

* **Unify Test Runner:** Use **Vitest for all tests** (both client and server). Remove Jest and related libraries from the project. This means eliminating `jest`, `babel-jest`, `ts-jest`, and `@types/jest` from devDependencies, as well as deleting `jest.config.js` and any Jest-specific setup files. For example, the package.json devDeps would no longer need the Jest entries (Jest 29.x, babel-jest, etc.). The test scripts can be updated accordingly (see below).

* **Vitest Configuration:** Expand Vitest’s config to cover back-end tests:

  * **Include all test files**: Adjust the `test.include` pattern in `vitest.config.ts` (currently limited to `tests/client/**/*`) to also include `tests/server/**/*.{test,spec}.{ts,tsx,js}`. This way, Vitest will pick up the API test files. If we convert the API tests to TypeScript (recommended), we’d use `.ts` extensions; otherwise include `.js` in the pattern.
  * **Test environment**: By default, Vitest was using `environment: 'jsdom'` globally for the client tests. We can keep JSDOM as the default (so that React tests continue to run in a DOM environment), but we need the server tests to run in a Node environment. Vitest allows per-file environment overrides. We should add a comment at the top of each server test file to force Node env, e.g. `// @vitest-environment node`. This will ensure those tests don’t get a JSDOM global (avoiding any performance hit or unwanted globals for server logic). Alternatively, Vitest could be configured with a custom pattern: for instance, if many server tests are grouped or share a filename convention, we could use Vitest’s config to assign `environment: 'node'` for that group. The simplest approach, though, is the per-file annotation.
  * **Global setup/teardown for DB**: We want to continue using **Testcontainers** to spin up a PostGIS database for the API tests, but we’ll handle it in Vitest. There are a couple of options:

    * Vitest supports a **`globalSetup`** function in config (since v3) that runs once before any tests. We can create a setup script (say `tests/setupGlobal.ts`) that calls our `startPg()` helper to launch the PostgreSQL container, run migrations, and seed the data. This script can store the container instance in a global variable (or within its closure) and then return a teardown function to stop the container after tests complete. Vitest will execute that teardown after all tests finish. This mimics what we intended with Jest’s globalSetup/globalTeardown (and uses the same `startPg` logic already in `tests/_setupDb.ts`).
    * If for some reason globalSetup is not used, an alternative is to initiate the DB container in the test suite itself. For example, in `api.test.ts` we could call `await startPg()` in a `beforeAll` hook at the top of the file, and call `container.stop()` in an `afterAll`. Since we run tests sequentially for a given file, this will set up the DB before the API tests and tear it down afterward. (With Vitest’s default behavior, test files may run in parallel threads, but if there’s only one integration test file, it will have its own thread. We might disable parallelization for safety, see below.)
    * **Environment variables**: Ensure that when the container starts, it sets `process.env.DATABASE_URL` for the tests. Our `startPg()` already does this. The Express app and pool will pick up this env var. We should also ensure the Express server doesn’t try to start its own listener (perhaps the tests should import an app instance that is not actively listening on a port, or use an in-memory server). In the current setup, `import app from '../../src/server/simplified-server.js'` brings in the Express app; as long as that file doesn’t call `.listen()` on a port during tests (it likely doesn’t, or else Supertest would conflict with a live server), we should be fine. If it does, we might adjust to import the Express app object instead of auto-starting the server in test mode.
    * **Test execution order**: If multiple integration test files are introduced later, to avoid launching multiple containers concurrently, we may configure Vitest’s test runner to run server tests serially. This can be done by tagging those tests or by setting `threads: false` for that portion. In practice, a single container for all tests (via globalSetup) is most efficient – it avoids duplication and ensures all API tests share the same seeded data. This also mirrors the current Jest approach where one container is used for the whole run.
  * **Mocking and utilities**: Bring over any Jest-specific test helpers into the Vitest world. For example, `@testing-library/jest-dom` provides custom DOM matchers (like `.toBeInTheDocument()`). In Jest it’s usually imported via setupFilesAfterEnv. In Vitest, we can import it in our setup file (`tests/client/setup.ts` which is already included) so that those matchers are available globally in Vitest tests as well. Also, Vitest uses `vi` as its global mocking API (analogous to `jest` global). Since we enabled `globals: true`, the standard `jest.fn()` calls in tests would need to be replaced with `vi.fn()` or simply use the global `fn` if provided. However, in our tests so far we haven’t used many Jest-specific globals (the client tests imported `vitest` explicitly, and the server test used a comment to enable globals). Thus, migrating should require minimal changes to test code.
  * **TypeScript adjustments**: If the API tests remain in JS, Vitest will run them fine. But we might consider converting `api.test.js` to **TypeScript** (e.g. rename to `api.test.ts`). This would allow us to get type checking on our test code and use imports of TypeScript modules without issues. Since Vitest/Vite handle TS transparently, this is mostly a rename plus adding type annotations if desired. The rest of the code (Supertest usage, etc.) can remain the same. All source code imports in tests can now point to the actual `.ts` files if we prefer (Vitest will compile them). For instance, if `simplified-server.js` is generated from a TypeScript source, we might import that source directly. Unifying on Vitest and ESM makes it easier to import our modules without worrying about file extensions or transpilation (one of the initial reasons to use plain JS in Jest).

* **NPM Scripts Simplification:** With one test runner, we can simplify the scripts in **package.json**:

  * Replace the separate `test:unit` and `test:api` scripts with a single **`test` script that runs Vitest** for all tests. For example: `"test": "vitest run --coverage"`. This will execute all tests and produce coverage. We no longer need to run two commands in sequence.
  * You can remove the now-obsolete `test:unit`, `test:api`, and `test:all` entries. If there’s a desire to keep the ability to run just one category (say, only client tests during development), we could reintroduce a pattern-based script (e.g. `"test:client": "vitest run tests/client"` and `"test:server": "vitest run tests/server"`), but that’s optional. The primary goal is that **`npm test`** runs everything with one framework.
  * Keep `test:e2e` (Playwright) as is for end-to-end tests. End-to-end tests are separate by nature (they require the app running and a browser), so those will remain on Playwright. We will likely run them independently in CI (potentially after the unit/integration tests pass).

* **Continuous Integration (CI) Updates:**

  * **Running tests:** Update the CI workflow to use the new unified test command. For example, if the GitHub Actions YAML currently does:

    ```yaml
    - name: Run tests with coverage
      run: npm run test && npx nyc report
    ```

    we can change this to simply `npm run test` (if we configure Vitest to output coverage on its own). Since Vitest can generate coverage reports using V8 instrumentation, we might not even need NYC for coverage. We can let Vitest output `coverage/*` files and have the Codecov action upload those. This simplifies CI because we run one tool instead of orchestrating NYC across two test runners.
  * **Coverage reporting:** If we remove NYC, ensure the Codecov action knows where to find the coverage results (Vitest by default will put them in `coverage/coverage-final.json` and an HTML report). We should also define coverage thresholds (Vitest can fail tests if coverage is below a certain percentage, or we can keep using Codecov’s gating rules). If we prefer to keep NYC for consistency, we could still run `nyc vitest run` to gather coverage – but that is likely unnecessary. Using Vitest’s built-in coverage (with `--coverage` flag or configuration) is more straightforward. In any case, the coverage output will now come from a single unified test run, which avoids the complication of merging reports from two different runners.
  * **Parallel execution:** Revisit whether running tests in parallel with e2e makes sense. Previously, `npm-run-all -p test:unit test:api test:e2e` was defined to run everything in parallel. This could be problematic (for example, the e2e tests start a Docker Compose stack which might conflict with the Testcontainer DB). With a single test runner, it might be better to run unit/integration tests *before* the Playwright tests, ensuring the database container from Testcontainers has been stopped. We can simplify by removing `test:all` (or changing it to run things sequentially). For instance, CI can run `npm run test` (Vitest) followed by `npm run test:e2e` (Playwright) as two separate steps. This will be more deterministic and resource-friendly than trying to run e2e in parallel with integration tests on the same machine.

By implementing these changes, the testing setup will be much simpler:

* **One framework (Vitest)** to install and maintain instead of two.
* **One combined test run** that covers both unit and API tests, with one consistent results output (making it easier to track failures and coverage).
* **Less config hackery**: no need for Babel or special Jest ESM handling. All tests run in the same module system (ESM) that the application code uses, via Vitest. The note in the plan about using plain JS for Jest due to ESM complications will no longer be an issue – we can write tests in TypeScript/ESM freely.
* **Consistent test APIs**: developers will use Vitest’s `expect/vi` for everything, and no longer have to switch mental context between Vitest and Jest syntax.

## Summary and Recommendations

In review, **ai-starter-app-postgis** currently splits testing between Vitest (for front-end) and Jest (for back-end). Test files are organized in `tests/client` and `tests/server` accordingly, and the package scripts clearly invoke each framework separately. The repository is a single-unit project (not a multi-package monorepo), so maintaining two test runners is mostly for technical preference rather than a structural need. Given the modern tooling in use, it’s both possible and advantageous to **standardize on a single test runner**.

I recommend **consolidating on Vitest** for all non-E2E tests, for its superior integration with the stack and simpler configuration. This entails adjusting the Vitest config to handle API tests (Node environment, database setup) and removing the Jest setup. The result will be a unified test workflow that preserves full coverage of both unit and integration scenarios without the overhead of two different frameworks. The CI pipeline will also be cleaner – running one set of tests and collecting one coverage report – and developers can run a single `npm test` to get feedback on all aspects of the application. Overall, this simplification will maintain the “comprehensive testing” goal but in a more maintainable way, leveraging Vitest’s capabilities to cover **both** frontend and backend testing needs.

**Sources:**

* Project README – test directories and scripts
* Vitest config (JSDOM for client tests)
* Jest config (Node env for server tests)
* Implementation Plan – rationale for using both Vitest & Jest and Testcontainers
* Example test files – Vitest UI test vs Jest API test which would be unified under one runner.
